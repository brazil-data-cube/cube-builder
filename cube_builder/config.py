#
# This file is part of Cube Builder.
# Copyright (C) 2022 INPE.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/gpl-3.0.html>.
#
"""Brazil Data Cube Configuration."""

import os

from .constants import to_bool
from .version import __version__

BASE_DIR = os.path.abspath(os.path.dirname(__file__))


def get_settings(env=None):
    """Retrieve Config class from environment."""
    if env is None:
        env = os.getenv('FLASK_ENV', 'development')

    return CONFIG.get(env)


class Config:
    """Base configuration with default flags.

    This file consists in default arguments flags for Data Cube Builder environment.

    Most of these settings can set configured using environment variables as following::

        export DATA_DIR=/data/
        export SQLALCHEMY_DATABASE_URI='postgresql://postgres:postgres@localhost:5432/bdc_catalog'
    """

    DEBUG = False
    TESTING = False

    # Factor to reserve tasks of the broker. By default, multiply by 1
    CELERYD_PREFETCH_MULTIPLIER = 1 * int(os.environ.get('CELERYD_PREFETCH_MULTIPLIER', 1))
    CBERS_AUTH_TOKEN = os.environ.get('CBERS_AUTH_TOKEN', '')
    # Path to store data
    ACTIVITIES_SCHEMA = 'cube_builder'
    DATA_DIR = os.environ.get('DATA_DIR', '/data')
    """Directory to store the published data.

    Inside this directory, the ``Cube-Builder`` will separate into ``identity`` and ``composed`` folders.
    Defaults to ``/data``."""
    WORK_DIR = os.environ.get('WORK_DIR', '/workdir')
    """Directory to generate temporary data.

    When the item is published, all the data inside ``WORK_DIR`` will be moved to ``DATA_DIR``.
    Its good practice to set different directory from ``DATA_DIR``.
    Inside this directory, the ``Cube-Builder`` will separate into ``identity`` and ``composed`` folders.
    Defaults to ``/workdir``."""
    RABBIT_MQ_URL = os.environ.get('RABBIT_MQ_URL', 'pyamqp://guest:guest@localhost')
    SQLALCHEMY_TRACK_MODIFICATIONS = False
    SQLALCHEMY_DATABASE_URI = os.environ.get(
        'SQLALCHEMY_DATABASE_URI',
        'postgresql://postgres:postgres@localhost:5432/bdc_catalog'
    )
    """The database URI that should be used for the database connection.
    Defaults to ``'postgresql://postgres:postgres@localhost:5432/bdc_catalog'``."""
    SQLALCHEMY_ENGINE_OPTIONS = {
        "pool_size": int(os.getenv("SQLALCHEMY_ENGINE_POOL_SIZE", 2)),
        "max_overflow": int(os.getenv("SQLALCHEMY_ENGINE_MAX_OVERFLOW", 5)),
        "poolclass": os.getenv("SQLALCHEMY_ENGINE_POOL_CLASS"),
        "pool_recycle": int(os.getenv("SQLALCHEMY_ENGINE_POOL_RECYCLE", -1)),
    }

    STAC_URL = os.environ.get('STAC_URL', 'https://brazildatacube.dpi.inpe.br/stac/')
    MAX_THREADS_IMAGE_VALIDATOR = int(os.environ.get('MAX_THREADS_IMAGE_VALIDATOR', os.cpu_count()))
    # rasterio
    RASTERIO_ENV = dict(
        GDAL_DISABLE_READDIR_ON_OPEN=True,
        GDAL_HTTP_UNSAFESSL=os.getenv('GDAL_HTTP_UNSAFESSL', 'NO')
    )
    # Access Token
    FLASK_ACCESS_TOKEN = os.getenv('FLASK_ACCESS_TOKEN', None)

    # Add prefix path to the items. Base path is /Repository
    # So the asset will be /Repository/Mosaic/collectionName/version/tile/period/scene.tif
    ITEM_PREFIX = os.getenv('ITEM_PREFIX', '/cubes')
    """Set custom item prefix.
    This is useful to "pre-append" a prefix in published items and be available by STAC server.
    Defaults to ``/cubes/``."""

    # BDC-Auth OAuth2
    BDC_AUTH_CLIENT_ID = os.getenv('BDC_AUTH_CLIENT_ID', None)
    """Client ID generated by BDC-Auth. 
    Defaults to ``None``. Used when ``BDC_AUTH_REQUIRED`` is set."""
    BDC_AUTH_CLIENT_SECRET = os.getenv('BDC_AUTH_CLIENT_SECRET', None)
    """Client secret generated by BDC-Auth. 
    Defaults to ``None``. Used when ``BDC_AUTH_REQUIRED`` is set."""
    BDC_AUTH_ACCESS_TOKEN_URL = os.getenv('BDC_AUTH_ACCESS_TOKEN_URL', None)
    """Access token url used for retrieving user info in BDC-Auth
    Defaults to ``None``. Used when ``BDC_AUTH_REQUIRED`` is set."""
    BDC_AUTH_REQUIRED = to_bool(os.getenv('BDC_AUTH_REQUIRED', '0'))
    """Flag to manage when a Auth is required.
    Defaults to ``0``, that means that there is not authorization request to access ``Cube Builder`` API."""

    # CBERS URL Prefix
    CBERS_SOURCE_URL_PREFIX = os.getenv('CBERS_SOURCE_URL_PREFIX', 'cdsr.dpi.inpe.br/api/download/TIFF')
    CBERS_TARGET_URL_PREFIX = os.getenv('CBERS_TARGET_URL_PREFIX', 'www.dpi.inpe.br/catalog/tmp')

    REDOC = {'title': 'Cube Builder API Doc', 'version': __version__}

    QUEUE_IDENTITY_CUBE = os.getenv('QUEUE_IDENTITY_CUBE', 'merge-cube')
    """Set a RabbitMQ queue name for Identity Data Cube generation.
        Defaults to ``merge-cube``."""
    QUEUE_PREPARE_CUBE = os.getenv('QUEUE_PREPARE_CUBE', 'prepare-cube')
    """Set a RabbitMQ queue name for Post Processing of Identity Data Cubes.
        Defaults to ``prepare-cube``."""
    QUEUE_BLEND_CUBE = os.getenv('QUEUE_BLEND_CUBE', 'blend-cube')
    """Set a RabbitMQ queue name for Composed Data Cubes generation.
            Defaults to ``blend-cube``."""
    QUEUE_PUBLISH_CUBE = os.getenv('QUEUE_PUBLISH_CUBE', 'publish-cube')
    """Set a RabbitMQ queue name for Publish Data Cubes.
            Defaults to ``publish-cube``."""
    QUEUE_TRIGGER_CUBE = os.getenv('QUEUE_TRIGGER_CUBE', 'trigger-cube')
    """Set a RabbitMQ queue name for Triggering Data Cubes.
            Defaults to ``trigger-cube``."""

    SQLALCHEMY_ENGINE_OPTIONS = {
        "pool_size": int(os.getenv("SQLALCHEMY_ENGINE_POOL_SIZE", 2)),
        "max_overflow": int(os.getenv("SQLALCHEMY_ENGINE_MAX_OVERFLOW", 5)),
        "poolclass": os.getenv("SQLALCHEMY_ENGINE_POOL_CLASS"),
        "pool_recycle": int(os.getenv("SQLALCHEMY_ENGINE_POOL_RECYCLE", -1)),
    }
    """Set SQLAlchemy engine options for pooling.
    You may set the following environment variables to customize pooling:
    
    - ``SQLALCHEMY_ENGINE_POOL_SIZE``: The pool size. Defaults to ``2``.
    - ``SQLALCHEMY_ENGINE_MAX_OVERFLOW``: Max pool overflow. Defaults to ``5``.
    - ``SQLALCHEMY_ENGINE_POOL_CLASS``: The pool type for management.
    - ``SQLALCHEMY_ENGINE_POOL_RECYCLE``: Define the given number of seconds to recycle pool. Defaults to ``-1``, or no timeout.
    """


class ProductionConfig(Config):
    """Production Mode."""

    DEBUG = False


class DevelopmentConfig(Config):
    """Development Mode."""

    DEVELOPMENT = True
    DEBUG = True


class TestingConfig(Config):
    """Testing Mode (Continous Integration)."""

    TESTING = True
    DEBUG = True


CONFIG = {
    "development": DevelopmentConfig(),
    "production": ProductionConfig(),
    "testing": TestingConfig()
}
